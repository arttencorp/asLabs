name: Backup Diario de Base de Datos
on:
  schedule:
    - cron: '30 5 * * *'
  workflow_dispatch:

jobs:
  backup-database:
    runs-on: ubuntu-latest
    
    steps:
      - name: Instalar herramientas necesarias (jq, PostgreSQL 17 client)
        run: |
          # Instalar jq
          sudo apt-get update && sudo apt-get install -y jq
          
          # Agregar repositorio oficial de PostgreSQL para obtener la versi√≥n 17
          sudo apt-get install -y wget ca-certificates
          
          # M√©todo moderno para agregar la clave GPG
          wget -qO- https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo tee /etc/apt/trusted.gpg.d/pgdg.asc &>/dev/null
          echo "deb http://apt.postgresql.org/pub/repos/apt/ $(lsb_release -cs)-pgdg main" | sudo tee /etc/apt/sources.list.d/pgdg.list
          
          # Actualizar e instalar PostgreSQL 17 client
          sudo apt-get update
          sudo apt-get install -y postgresql-client-17 python3-pip
          
          # Instalar Google Drive API
          pip3 install google-api-python-client google-auth google-auth-oauthlib google-auth-httplib2
          
          # Verificar instalaci√≥n
          echo "Versi√≥n de pg_dump instalada:"
          /usr/lib/postgresql/17/bin/pg_dump --version || pg_dump --version

      - name: Configurar variables de fecha
        id: config
        run: |
          echo "date=$(date +'%Y-%m-%d_%H-%M-%S')" >> $GITHUB_OUTPUT
          echo "date_simple=$(date +'%Y-%m-%d')" >> $GITHUB_OUTPUT

      - name: Autorizar IP del Runner en el firewall de Supabase
        id: authorize_ip
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
          PROJECT_ID: ${{ secrets.SUPABASE_PROJECT_ID }}
        run: |
          RUNNER_IP=$(curl -s ifconfig.me)
          echo "La IP del Runner es: $RUNNER_IP"
          
          CURRENT_RULES_JSON=$(curl -s -f -X GET \
            "https://api.supabase.com/v1/projects/$PROJECT_ID/network-restrictions" \
            -H "Authorization: Bearer $SUPABASE_ACCESS_TOKEN")
          
          if [ $? -ne 0 ]; then
            echo "::error::Fall√≥ la obtenci√≥n de las reglas de red. ¬øEl PROJECT_ID y el ACCESS_TOKEN son correctos?"
            exit 1
          fi
          
          echo "original_rules=$CURRENT_RULES_JSON" >> $GITHUB_OUTPUT

          NEW_RULES_JSON=$(echo "$CURRENT_RULES_JSON" | jq --arg ip "$RUNNER_IP/32" '.dbAllowedCidrs += [$ip]')

          echo "Aplicando nuevas reglas de red para permitir la IP: $RUNNER_IP..."
          curl -s -f -X POST \
            "https://api.supabase.com/v1/projects/$PROJECT_ID/network-restrictions/apply" \
            -H "Authorization: Bearer $SUPABASE_ACCESS_TOKEN" \
            -H "Content-Type: application/json" \
            --data-raw "$NEW_RULES_JSON"
          
          if [ $? -ne 0 ]; then
            echo "::error::Fall√≥ al aplicar las nuevas reglas de red."
            exit 1
          fi

          echo "Esperando 15 segundos para que la regla se aplique..."
          sleep 15

      - name: Crear backup de la Base de Datos
        id: backup
        env:
          # Usamos la URL directa (sin pooler)
          DATABASE_URL: ${{ secrets.SUPABASE_DATABASE_URL }}
        run: |
          echo "Verificando versi√≥n de pg_dump..."
          # Intentar usar la versi√≥n espec√≠fica de PostgreSQL 17 primero
          PG_DUMP_CMD="/usr/lib/postgresql/17/bin/pg_dump"
          if [ ! -f "$PG_DUMP_CMD" ]; then
            echo "PostgreSQL 17 no encontrado, usando versi√≥n por defecto..."
            PG_DUMP_CMD="pg_dump"
          fi
          
          $PG_DUMP_CMD --version
          
          echo "Iniciando backup..."
          FILENAME="supabase-backup-${{ steps.config.outputs.date }}.sql"
          
          # Usar pg_dump con mejor compatibilidad de versiones
          $PG_DUMP_CMD "$DATABASE_URL" \
            --no-owner \
            --no-privileges \
            --clean \
            --if-exists \
            --verbose \
            > $FILENAME
          
          # Si falla por incompatibilidad de versiones, intentar con Docker
          if [ $? -ne 0 ]; then
            echo "::warning::pg_dump fall√≥, intentando con Docker PostgreSQL 17..."
            docker run --rm \
              -e PGPASSWORD="$(echo "$DATABASE_URL" | sed -n 's/.*:\([^@]*\)@.*/\1/p')" \
              postgres:17 \
              pg_dump \
              --host="$(echo "$DATABASE_URL" | sed -n 's/.*@\([^:]*\):.*/\1/p')" \
              --port="$(echo "$DATABASE_URL" | sed -n 's/.*:\([0-9]*\)\/.*/\1/p')" \
              --username="$(echo "$DATABASE_URL" | sed -n 's/.*\/\/\([^:]*\):.*/\1/p')" \
              --dbname="$(echo "$DATABASE_URL" | sed -n 's/.*\/\([^?]*\).*/\1/p')" \
              --no-owner \
              --no-privileges \
              --clean \
              --if-exists \
              --verbose \
              > $FILENAME
              
            if [ $? -ne 0 ]; then
              echo "::error::Fall√≥ la creaci√≥n del backup con Docker tambi√©n"
              exit 1
            fi
          fi
          
          # Verificar que el archivo no est√© vac√≠o
          if [ ! -s "$FILENAME" ]; then
            echo "::error::El archivo de backup est√° vac√≠o"
            exit 1
          fi
          
          echo "Comprimiendo backup..."
          tar -czf "$FILENAME.tar.gz" $FILENAME
          
          SIZE=$(ls -lh "$FILENAME.tar.gz" | awk '{print $5}')
          echo "size_compressed=$SIZE" >> $GITHUB_OUTPUT
          echo "Backup creado exitosamente: $SIZE"
      
      - name: Subir backup a Google Drive
        env:
          GOOGLE_DRIVE_CREDENTIALS: ${{ secrets.GOOGLE_DRIVE_CREDENTIALS }}
          GOOGLE_DRIVE_FOLDER_ID: ${{ secrets.GOOGLE_DRIVE_FOLDER_ID }}
        run: |
          echo "Configurando credenciales de Google Drive..."
          echo '${{ secrets.GOOGLE_DRIVE_CREDENTIALS }}' > /tmp/credentials.json
          
          echo "Creando script de subida a Google Drive..."
          cat > upload_to_drive.py << 'EOF'
          import os
          import json
          from google.oauth2 import service_account
          from googleapiclient.discovery import build
          from googleapiclient.http import MediaFileUpload
          from datetime import datetime
          
          def upload_to_drive():
              # Cargar credenciales
              credentials = service_account.Credentials.from_service_account_file(
                  '/tmp/credentials.json',
                  scopes=['https://www.googleapis.com/auth/drive.file']
              )
              
              # Crear servicio de Drive
              service = build('drive', 'v3', credentials=credentials)
              
              # Buscar el archivo backup
              import glob
              backup_files = glob.glob('*.tar.gz')
              if not backup_files:
                  print("No se encontr√≥ archivo de backup")
                  return False
                  
              backup_file = backup_files[0]
              print(f"Subiendo archivo: {backup_file}")
              
              # Configurar metadata del archivo
              file_metadata = {
                  'name': backup_file,
                  'parents': [os.environ.get('GOOGLE_DRIVE_FOLDER_ID')]
              }
              
              # Subir archivo
              media = MediaFileUpload(backup_file, resumable=True)
              file = service.files().create(
                  body=file_metadata,
                  media_body=media,
                  fields='id'
              ).execute()
              
              print(f"Archivo subido exitosamente. ID: {file.get('id')}")
              return True
          
          if __name__ == '__main__':
              try:
                  if upload_to_drive():
                      print("‚úÖ Backup subido a Google Drive exitosamente")
                  else:
                      print("‚ùå Error al subir backup a Google Drive")
                      exit(1)
              except Exception as e:
                  print(f"‚ùå Error: {str(e)}")
                  exit(1)
          EOF
          
          echo "Ejecutando subida a Google Drive..."
          python3 upload_to_drive.py
      
      - name: Subir backup como artefacto
        uses: actions/upload-artifact@v4
        with:
          name: backup-${{ steps.config.outputs.date }}
          path: "*.tar.gz"
          retention-days: 30
      
      - name: Enviar notificaci√≥n de √©xito
        if: success()
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 465
          secure: true
          username: ${{ secrets.EMAIL_USERNAME }}
          password: ${{ secrets.EMAIL_PASSWORD }}
          subject: Backup Exitoso - ${{ steps.config.outputs.date_simple }}
          to: ${{ secrets.EMAIL_USERNAME }}
          from: GitHub Actions <${{ secrets.EMAIL_USERNAME }}>
          body: |
            El backup de la base de datos se complet√≥ exitosamente.
            Tama√±o del archivo comprimido: ${{ steps.backup.outputs.size_compressed }}
            
            üì¶ GitHub Actions: Desc√°rgalo desde la secci√≥n de Artefactos
            ‚òÅÔ∏è Google Drive: Subido autom√°ticamente a la carpeta configurada
            
            Fecha del backup: ${{ steps.config.outputs.date }}
            
      - name: Limpiar y restaurar firewall (SIEMPRE SE EJECUTA)
        if: always()
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
          PROJECT_ID: ${{ secrets.SUPABASE_PROJECT_ID }}
          ORIGINAL_RULES: ${{ steps.authorize_ip.outputs.original_rules }}
        run: |
          echo "Limpiando archivos locales..."
          rm -f *.sql *.tar.gz upload_to_drive.py /tmp/credentials.json
          
          echo "Restaurando reglas originales del firewall..."
          if [[ -n "$ORIGINAL_RULES" && "$ORIGINAL_RULES" != *"Cannot GET"* ]]; then
            curl -s -X POST \
              "https://api.supabase.com/v1/projects/$PROJECT_ID/network-restrictions/apply" \
              -H "Authorization: Bearer $SUPABASE_ACCESS_TOKEN" \
              -H "Content-Type: application/json" \
              -d "$ORIGINAL_RULES"
            echo "Firewall restaurado a su estado original."
          else
            echo "No se encontraron reglas originales v√°lidas para restaurar, omitiendo."
          fi