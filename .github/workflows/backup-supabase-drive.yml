name: Backup Diario de Base de Datos
on:
  schedule:
    - cron: '30 5 * * *'
  workflow_dispatch:

jobs:
  backup-database:
    runs-on: ubuntu-latest
    
    steps:
      - name: Instalar herramientas necesarias (jq, PostgreSQL 17 client)
        run: |
          # Instalar jq
          sudo apt-get update && sudo apt-get install -y jq
          
          # Agregar repositorio oficial de PostgreSQL para obtener la versión 17
          sudo apt-get install -y wget ca-certificates
          
          # Método moderno para agregar la clave GPG
          wget -qO- https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo tee /etc/apt/trusted.gpg.d/pgdg.asc &>/dev/null
          echo "deb http://apt.postgresql.org/pub/repos/apt/ $(lsb_release -cs)-pgdg main" | sudo tee /etc/apt/sources.list.d/pgdg.list
          
          # Actualizar e instalar PostgreSQL 17 client
          sudo apt-get update
          sudo apt-get install -y postgresql-client-17 python3-pip
          
          # Instalar Google Drive API
          pip3 install google-api-python-client google-auth google-auth-oauthlib google-auth-httplib2
          
          # Verificar instalación
          echo "Versión de pg_dump instalada:"
          /usr/lib/postgresql/17/bin/pg_dump --version || pg_dump --version

      - name: Configurar variables de fecha
        id: config
        run: |
          echo "date=$(date +'%Y-%m-%d_%H-%M-%S')" >> $GITHUB_OUTPUT
          echo "date_simple=$(date +'%Y-%m-%d')" >> $GITHUB_OUTPUT

      - name: Autorizar IP del Runner en el firewall de Supabase
        id: authorize_ip
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
          PROJECT_ID: ${{ secrets.SUPABASE_PROJECT_ID }}
        run: |
          RUNNER_IP=$(curl -s ifconfig.me)
          echo "La IP del Runner es: $RUNNER_IP"
          
          CURRENT_RULES_JSON=$(curl -s -f -X GET \
            "https://api.supabase.com/v1/projects/$PROJECT_ID/network-restrictions" \
            -H "Authorization: Bearer $SUPABASE_ACCESS_TOKEN")
          
          if [ $? -ne 0 ]; then
            echo "::error::Falló la obtención de las reglas de red. ¿El PROJECT_ID y el ACCESS_TOKEN son correctos?"
            exit 1
          fi
          
          echo "original_rules=$CURRENT_RULES_JSON" >> $GITHUB_OUTPUT

          NEW_RULES_JSON=$(echo "$CURRENT_RULES_JSON" | jq --arg ip "$RUNNER_IP/32" '.dbAllowedCidrs += [$ip]')

          echo "Aplicando nuevas reglas de red para permitir la IP: $RUNNER_IP..."
          curl -s -f -X POST \
            "https://api.supabase.com/v1/projects/$PROJECT_ID/network-restrictions/apply" \
            -H "Authorization: Bearer $SUPABASE_ACCESS_TOKEN" \
            -H "Content-Type: application/json" \
            --data-raw "$NEW_RULES_JSON"
          
          if [ $? -ne 0 ]; then
            echo "::error::Falló al aplicar las nuevas reglas de red."
            exit 1
          fi

          echo "Esperando 15 segundos para que la regla se aplique..."
          sleep 15

      - name: Crear backup de la Base de Datos
        id: backup
        env:
          # Usamos la URL directa (sin pooler)
          DATABASE_URL: ${{ secrets.SUPABASE_DATABASE_URL }}
        run: |
          echo "Verificando versión de pg_dump..."
          # Intentar usar la versión específica de PostgreSQL 17 primero
          PG_DUMP_CMD="/usr/lib/postgresql/17/bin/pg_dump"
          if [ ! -f "$PG_DUMP_CMD" ]; then
            echo "PostgreSQL 17 no encontrado, usando versión por defecto..."
            PG_DUMP_CMD="pg_dump"
          fi
          
          $PG_DUMP_CMD --version
          
          echo "Iniciando backup..."
          FILENAME="supabase-backup-${{ steps.config.outputs.date }}.sql"
          
          # Usar pg_dump con mejor compatibilidad de versiones
          $PG_DUMP_CMD "$DATABASE_URL" \
            --no-owner \
            --no-privileges \
            --clean \
            --if-exists \
            --verbose \
            > $FILENAME
          
          # Si falla por incompatibilidad de versiones, intentar con Docker
          if [ $? -ne 0 ]; then
            echo "::warning::pg_dump falló, intentando con Docker PostgreSQL 17..."
            docker run --rm \
              -e PGPASSWORD="$(echo "$DATABASE_URL" | sed -n 's/.*:\([^@]*\)@.*/\1/p')" \
              postgres:17 \
              pg_dump \
              --host="$(echo "$DATABASE_URL" | sed -n 's/.*@\([^:]*\):.*/\1/p')" \
              --port="$(echo "$DATABASE_URL" | sed -n 's/.*:\([0-9]*\)\/.*/\1/p')" \
              --username="$(echo "$DATABASE_URL" | sed -n 's/.*\/\/\([^:]*\):.*/\1/p')" \
              --dbname="$(echo "$DATABASE_URL" | sed -n 's/.*\/\([^?]*\).*/\1/p')" \
              --no-owner \
              --no-privileges \
              --clean \
              --if-exists \
              --verbose \
              > $FILENAME
              
            if [ $? -ne 0 ]; then
              echo "::error::Falló la creación del backup con Docker también"
              exit 1
            fi
          fi
          
          # Verificar que el archivo no esté vacío
          if [ ! -s "$FILENAME" ]; then
            echo "::error::El archivo de backup está vacío"
            exit 1
          fi
          
          echo "Comprimiendo backup..."
          tar -czf "$FILENAME.tar.gz" $FILENAME
          
          SIZE=$(ls -lh "$FILENAME.tar.gz" | awk '{print $5}')
          echo "size_compressed=$SIZE" >> $GITHUB_OUTPUT
          echo "Backup creado exitosamente: $SIZE"
      
      - name: Subir backup a Google Drive
        id: drive_upload
        continue-on-error: true
        env:
          GOOGLE_DRIVE_CREDENTIALS: ${{ secrets.GOOGLE_DRIVE_CREDENTIALS }}
          GOOGLE_DRIVE_FOLDER_ID: ${{ secrets.GOOGLE_DRIVE_FOLDER_ID }}
        run: |
          echo "Configurando credenciales de Google Drive..."
          echo '${{ secrets.GOOGLE_DRIVE_CREDENTIALS }}' > /tmp/credentials.json
          
          # Verificar que las credenciales sean válidas JSON
          if ! python3 -m json.tool /tmp/credentials.json > /dev/null 2>&1; then
            echo "Error: Las credenciales de Google Drive no son JSON válido"
            echo "google_drive_status=❌ Error de configuración" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Verificar que GOOGLE_DRIVE_FOLDER_ID esté configurado
          if [[ -z "${{ secrets.GOOGLE_DRIVE_FOLDER_ID }}" ]]; then
            echo "Error: GOOGLE_DRIVE_FOLDER_ID no está configurado"
            echo "google_drive_status=❌ Error de configuración" >> $GITHUB_OUTPUT
            exit 0
          fi

          echo "Creando script de subida a Google Drive..."
          cat > upload_to_drive.py << 'EOF'
import os
import json
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
from googleapiclient.errors import HttpError
from datetime import datetime

def upload_to_drive():
    try:
        credentials = service_account.Credentials.from_service_account_file(
            '/tmp/credentials.json',
            scopes=['https://www.googleapis.com/auth/drive']
        )
        
        service = build('drive', 'v3', credentials=credentials)
        
        import glob
        backup_files = glob.glob('*.tar.gz')
        if not backup_files:
            print("No se encontró archivo de backup")
            return False
            
        backup_file = backup_files[0]
        print(f"Subiendo archivo: {backup_file}")
        
        file_size = os.path.getsize(backup_file)
        print(f"Tamaño del archivo: {file_size} bytes")
        
        folder_id = os.environ.get('GOOGLE_DRIVE_FOLDER_ID')
        if not folder_id:
            print("Error: GOOGLE_DRIVE_FOLDER_ID no está configurado")
            return False
        
        try:
            folder_info = service.files().get(fileId=folder_id).execute()
            print(f"Carpeta de destino: {folder_info.get('name', 'Sin nombre')}")
        except HttpError as e:
            if e.resp.status == 404:
                print(f"Error: La carpeta con ID {folder_id} no existe o no es accesible")
                return False
            raise
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        file_name = f"supabase_backup_{timestamp}.tar.gz"
        
        file_metadata = {
            'name': file_name,
            'parents': [folder_id]
        }
        
        if file_size < 5 * 1024 * 1024:
            media = MediaFileUpload(backup_file)
            file = service.files().create(
                body=file_metadata,
                media_body=media,
                fields='id,name,size,createdTime'
            ).execute()
        else:
            media = MediaFileUpload(backup_file, resumable=True)
            file = service.files().create(
                body=file_metadata,
                media_body=media,
                fields='id,name,size,createdTime'
            ).execute()
        
        print(f"Backup subido exitosamente a Google Drive")
        print(f"ID: {file.get('id')}")
        print(f"Nombre: {file.get('name')}")
        print(f"Tamaño: {file.get('size')} bytes")
        print(f"Creado: {file.get('createdTime')}")
        return True
        
    except HttpError as e:
        if e.resp.status == 403 and 'storageQuotaExceeded' in str(e):
            print("Error: Sin cuota de almacenamiento. Verifica que:")
            print("1. La cuenta de servicio tenga acceso a una unidad compartida")
            print("2. O que esté usando delegación OAuth")
            print("3. O que la carpeta de destino esté en una unidad compartida")
        else:
            print(f"Error HTTP: {e}")
        return False
    except Exception as e:
        print(f"Error inesperado: {str(e)}")
        return False

if __name__ == '__main__':
    if upload_to_drive():
        print("Proceso completado exitosamente")
    else:
        print("Proceso falló - continuando sin Google Drive")
EOF

          echo "Ejecutando subida a Google Drive..."
          if python3 upload_to_drive.py; then
            echo "google_drive_status=✅ Exitoso" >> $GITHUB_OUTPUT
          else
            echo "google_drive_status=⚠️ Falló (backup disponible en GitHub Actions)" >> $GITHUB_OUTPUT
          fi
      
      - name: Subir backup como artefacto
        uses: actions/upload-artifact@v4
        with:
          name: backup-${{ steps.config.outputs.date }}
          path: "*.tar.gz"
          retention-days: 30
      
      - name: Enviar notificación de éxito
        if: success()
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 465
          secure: true
          username: ${{ secrets.EMAIL_USERNAME }}
          password: ${{ secrets.EMAIL_PASSWORD }}
          subject: Backup Exitoso - ${{ steps.config.outputs.date_simple }}
          to: ${{ secrets.EMAIL_USERNAME }}
          from: GitHub Actions <${{ secrets.EMAIL_USERNAME }}>
          body: |
            El backup de la base de datos se completó exitosamente.
            Tamaño del archivo comprimido: ${{ steps.backup.outputs.size_compressed }}
            
            📦 GitHub Actions: Descárgalo desde la sección de Artefactos
            ☁️ Google Drive: ${{ steps.drive_upload.outputs.google_drive_status }}
            
            Fecha del backup: ${{ steps.config.outputs.date }}
            
      - name: Limpiar y restaurar firewall (SIEMPRE SE EJECUTA)
        if: always()
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
          PROJECT_ID: ${{ secrets.SUPABASE_PROJECT_ID }}
          ORIGINAL_RULES: ${{ steps.authorize_ip.outputs.original_rules }}
        run: |
          echo "Limpiando archivos locales..."
          rm -f *.sql *.tar.gz upload_to_drive.py /tmp/credentials.json
          
          echo "Restaurando reglas originales del firewall..."
          if [[ -n "$ORIGINAL_RULES" && "$ORIGINAL_RULES" != *"Cannot GET"* ]]; then
            curl -s -X POST \
              "https://api.supabase.com/v1/projects/$PROJECT_ID/network-restrictions/apply" \
              -H "Authorization: Bearer $SUPABASE_ACCESS_TOKEN" \
              -H "Content-Type: application/json" \
              -d "$ORIGINAL_RULES"
            echo "Firewall restaurado a su estado original."
          else
            echo "No se encontraron reglas originales válidas para restaurar, omitiendo."
          fi